{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2aa91e3-a04f-47d9-88ca-95f30f6f9bac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Structure segmentation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1eb24bb0-2934-40b4-bcc0-79b6a556ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from choco_utils.dataloader import ChoCoHarteAnnotationsSectionCorpus\n",
    "from segmentation.metrics import under_over_segmentation, pairwise_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ec1bdac-afb9-483b-87b9-d9e211fc5741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/jams/core.py:878: UserWarning: Annotation.duration is not defined, cannot check for temporal intersection, assuming the annotation is valid between start_time and end_time.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = ChoCoHarteAnnotationsSectionCorpus(\"/home/n28div/university/thesis/choco/\")\n",
    "dataset = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0962e00-0514-4e0e-bf63-a2eecb0a6bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 21847 annotations - 168 unique\n"
     ]
    }
   ],
   "source": [
    "sections = [ann.section for doc in dataset for ann in doc.annotations]\n",
    "print(f\"Total of {len(sections)} annotations - {len(set(sections))} unique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44706a83-7720-4a0e-b268-f937f7c7f65c",
   "metadata": {},
   "source": [
    "Unify most sections as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9bd4ce87-6fad-487e-8a17-66e97cf7cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import functools\n",
    "import string\n",
    "\n",
    "SYMBOLS_RE = re.compile(\"[\" + re.escape(string.punctuation) + \"]\")\n",
    "NUMBERS_RE = re.compile(\"[\" + re.escape(string.digits) + \"]\")\n",
    "CONSECUTIVE_SPACES_RE = re.compile(r\"\\s+\")\n",
    "INTRO_RE = re.compile(r\".*(intro|beginning).*\")\n",
    "VERSE_RE = re.compile(r\".*(verse).*\")\n",
    "REFRAIN_RE = re.compile(r\".*(refrain).*\")\n",
    "BRIDGE_RE = re.compile(r\".*(bridge).*\")\n",
    "CHORUS_RE = re.compile(r\".*(chorus|c).*\")\n",
    "INSTRUMENTAL_RE = re.compile(r\".*(instumental|instrumental|ad\\s?lib).*\")\n",
    "SOLO_RE = re.compile(r\".*(solo|vocal).*\")\n",
    "OUTRO_RE = re.compile(r\".*(outro|ending|fade\\s?out|closing|end|coda).*\")\n",
    "\n",
    "def preprocess_section(section):\n",
    "  # remove symbols, numbers and spaces\n",
    "  section = SYMBOLS_RE.sub(\" \", section)\n",
    "  section = NUMBERS_RE.sub(\" \", section)\n",
    "  section = CONSECUTIVE_SPACES_RE.sub(\" \", section)\n",
    "  # remove word half, break\n",
    "  section = section.replace(\"half\", \"\")\n",
    "  section = section.replace(\"break\", \"\")\n",
    "  # if [*beginning*, *intro*] -> intro\n",
    "  section = \"intro\" if INTRO_RE.match(section) else section\n",
    "  # if *verse* -> verse\n",
    "  section = \"verse\" if VERSE_RE.match(section) else section\n",
    "  # if *refrain* -> refrain\n",
    "  section = \"refrain\" if REFRAIN_RE.match(section) else section\n",
    "  # if *bridge* -> bridge\n",
    "  section = \"bridge\" if BRIDGE_RE.match(section) else section\n",
    "  # if *bridge* -> bridge\n",
    "  section = \"chorus\" if CHORUS_RE.match(section) else section\n",
    "  # if [*instrumental*, *ad lib*] -> instrumental\n",
    "  section = \"instrumental\" if INSTRUMENTAL_RE.match(section) else section\n",
    "  # if [*solo*, *vocal*] -> solo\n",
    "  section = \"solo\" if SOLO_RE.match(section) else section\n",
    "  # if [*outro*, *ending*, *fade out*, *closing*, *end*, *coda*] -> outro\n",
    "  section = \"outro\" if OUTRO_RE.match(section) else section\n",
    "  # everything not in [bridge, chorus, instrumental, interlude, intro, outro, refrain, solo, verse]\n",
    "  # -> part\n",
    "  section = section if section in [\"bridge\", \"chorus\", \"instrumental\", \"interlude\", \"intro\", \"outro\", \"refrain\", \"solo\", \"verse\"] else \"part\"\n",
    "  # strip whitespaces\n",
    "  section = section.strip()\n",
    "  return section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6a87050-fa61-4208-8dfa-91b6bed3eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from choco_utils.dataloader import HarteAnnotation, HarteSectionAnnotation\n",
    "dataset = [[HarteSectionAnnotation(HarteAnnotation(*ann.chord), preprocess_section(ann.section)) for ann in doc.annotations] for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a905b0d-ff02-43dc-8d80-256f229585a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 21847 annotations - 10 unique\n"
     ]
    }
   ],
   "source": [
    "sections = [ann.section for sample in dataset for ann in sample]\n",
    "print(f\"Total of {len(sections)} annotations - {len(set(sections))} unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6806c09b-1d5c-4a38-bb45-cb1b0e61d3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(verse)        = 0.4529 ( 9894 apparences)\n",
      "p(refrain)      = 0.1621 ( 3541 apparences)\n",
      "p(bridge)       = 0.1210 ( 2644 apparences)\n",
      "p(outro)        = 0.0850 ( 1856 apparences)\n",
      "p(intro)        = 0.0674 ( 1473 apparences)\n",
      "p(chorus)       = 0.0570 ( 1246 apparences)\n",
      "p(instrumental) = 0.0271 (  592 apparences)\n",
      "p(part)         = 0.0225 (  492 apparences)\n",
      "p(solo)         = 0.0032 (   71 apparences)\n",
      "p(interlude)    = 0.0017 (   38 apparences)\n"
     ]
    }
   ],
   "source": [
    "sections_frequency = collections.Counter(sections)\n",
    "section_p = { s: c / sum(sections_frequency.values()) for s, c in sections_frequency.items() }\n",
    "\n",
    "for section, freq in sorted(sections_frequency.items(), key=lambda t: t[1], reverse=True):\n",
    "  print(f\"p({section})\".ljust(15, \" \"), f\"= {freq / sum(sections_frequency.values()):0.4f} ({str(freq).rjust(5, ' ')} apparences)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28427ec-30c6-4f51-ba26-492dc3cbbbd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36bf7236-cbf0-4c16-ada9-f233edd37f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def contigous_clusters(segmentation):\n",
    "  _, seg = np.unique(segmentation, return_inverse=True)\n",
    "  return seg\n",
    "\n",
    "\n",
    "# assign a number (its index) to each section and repeat that number for the constituents of that\n",
    "# category\n",
    "def extract_labels_from_sample(sample):\n",
    "  annotated_seg = np.array(list(itertools.chain(*[itertools.repeat(name, len(content)) \n",
    "                                                  for name, _, _, content in sample[\"structure\"]])))\n",
    "\n",
    "  return contigous_clusters(annotated_seg)\n",
    "\n",
    "le = LabelEncoder().fit(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "adbb0ff6-6302-4c10-badb-a6e38dd00299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 45)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# select 20% of data as testing\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2cb5bf17-cd00-4761-903d-cf473d2e85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.form import FORM\n",
    "\n",
    "pairwise = list()\n",
    "under_over = list()\n",
    "for sample in test:\n",
    "  target = contigous_clusters(le.transform([ann.section.lower() for ann in sample if ann is not None]))\n",
    "  pred = contigous_clusters(FORM([ann.chord.symbol for ann in sample if ann is not None]))\n",
    "  pairwise.append(pairwise_metrics(target, pred))\n",
    "  under_over.append(under_over_segmentation(target, pred))\n",
    "  \n",
    "precision, recall, f1 = np.array(pairwise).mean(axis=0)\n",
    "under, over = np.array(under_over).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f02af36-34e2-4920-8008-4a6409626a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5977847975050611,\n",
       " 0.4668899718385443,\n",
       " 0.5073480807364139,\n",
       " 0.47410357150806065,\n",
       " 0.6019579515576962)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, under, over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "892ecae0-25d4-4e85-a097-17a90c1fcecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_sample(sample, context_size = 3):\n",
    "  if context_size == -1:\n",
    "    context_size = len(sample) - 1\n",
    "  \n",
    "  offset = tuple(range(-1 * context_size, context_size + 1))\n",
    "  window =  list(mitertools.stagger(sample, offset))\n",
    "  return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b0bc0b27-2675-4d65-a106-c9ef57c9271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_embedding(model, window, weighted_mean = False, weighted_distance = False, log_weight_distance = False):\n",
    "  chords = map(lambda w: w.chord.symbol if w is not None else None, window)\n",
    "  \n",
    "  # map chords to embedding\n",
    "  context = np.stack(list(map(lambda c: model[c] if c is not None else np.zeros(model.embedding_dim), chords)))\n",
    "  \n",
    "  weights = np.ones(len(window))\n",
    "  \n",
    "  if weighted_mean:\n",
    "    weights *= np.array([w.chord.duration if w is not None else 0 for w in window])\n",
    "    \n",
    "  if weighted_distance:\n",
    "    seq_len = len(window) // 2\n",
    "    dist_weight = np.abs(np.arange(-1.0 * seq_len, seq_len + 1.0)) + 1\n",
    "    if log_weight_distance:\n",
    "      dist_weight = np.log(dist_weight + 1)\n",
    "    weights *= 1 / dist_weight\n",
    "  \n",
    "  context = np.average(context, axis=0, weights=weights)\n",
    "  \n",
    "  return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "81893433-9893-49ad-a668-69ce4cc38f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sample(model, sample, context_size = 4, weighted_mean = False, weighted_distance = False, log_weight_distance=False):\n",
    "  windows = window_sample(sample, context_size=4)\n",
    "  for annotated_chord, window in zip(sample, windows):\n",
    "    context = context_embedding(model, window, weighted_mean=weighted_mean, weighted_distance=weighted_distance, log_weight_distance=log_weight_distance)\n",
    "    chord_embedding = model[annotated_chord.chord.symbol]\n",
    "\n",
    "    X = np.concatenate([chord_embedding, context])\n",
    "    y = annotated_chord.section.lower()\n",
    "    yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "388d79ca-73ae-40fb-bf34-5e63eed6bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_data(model, data, context_size = 4, weighted_mean = False, weighted_distance = False, log_weight_distance=False):\n",
    "  embed_fn = partial(embed_sample, model, context_size=context_size, weighted_mean=weighted_mean, weighted_distance=weighted_distance, log_weight_distance=log_weight_distance)\n",
    "  # map to all data sample the embed function, concatenate all those results and split\n",
    "  # the arrays of 2-tuples into 2-tuple of two arrays\n",
    "  return zip(*itertools.chain(*map(embed_fn, data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c81aa329-5d73-416a-a3f0-a3f85e708483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_from_classifier(clf, embedding_model, sample, embed_params = {}):\n",
    "  embedded_sample, _ = zip(*embed_sample(embedding_model, sample, **embed_params))\n",
    "  embedded_sample = np.stack(embedded_sample)\n",
    "  pred = clf.predict(embedded_sample)\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f0bacff-e79d-453c-b1e4-430bad73c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_prediction(le, section_p, pred):\n",
    "  for i, (p, c, n) in enumerate(mitertools.stagger(pred)):  \n",
    "    if p != None and p != c != n:\n",
    "      p_p = section_p[le.inverse_transform([p])[0]]\n",
    "      p_n = section_p[le.inverse_transform([n])[0]]\n",
    "      pred[i] = p if p_p > p_n else n\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb7065-337f-4825-882c-130418b1f9a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f519a-38ba-4fdd-93fc-bc5d7eaa16cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### As a classification problem: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f9b985ee-17f1-4902-a890-69c1425f2fe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word2Vec' object has no attribute 'embedding_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[0;32m----> 4\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43membed_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword2vec_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(X)\n\u001b[1;32m      7\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit(sections)\n",
      "Input \u001b[0;32mIn [83]\u001b[0m, in \u001b[0;36membed_data\u001b[0;34m(model, data, context_size, weighted_mean, weighted_distance, log_weight_distance)\u001b[0m\n\u001b[1;32m      2\u001b[0m embed_fn \u001b[38;5;241m=\u001b[39m partial(embed_sample, model, context_size\u001b[38;5;241m=\u001b[39mcontext_size, weighted_mean\u001b[38;5;241m=\u001b[39mweighted_mean, weighted_distance\u001b[38;5;241m=\u001b[39mweighted_distance, log_weight_distance\u001b[38;5;241m=\u001b[39mlog_weight_distance)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# map to all data sample the embed function, concatenate all those results and split\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# the arrays of 2-tuples into 2-tuple of two arrays\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membed_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [82]\u001b[0m, in \u001b[0;36membed_sample\u001b[0;34m(model, sample, context_size, weighted_mean, weighted_distance, log_weight_distance)\u001b[0m\n\u001b[1;32m      2\u001b[0m windows \u001b[38;5;241m=\u001b[39m window_sample(sample, context_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m annotated_chord, window \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sample, windows):\n\u001b[0;32m----> 4\u001b[0m   context \u001b[38;5;241m=\u001b[39m \u001b[43mcontext_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_weight_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_weight_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   chord_embedding \u001b[38;5;241m=\u001b[39m model[annotated_chord\u001b[38;5;241m.\u001b[39mchord\u001b[38;5;241m.\u001b[39msymbol]\n\u001b[1;32m      7\u001b[0m   X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([chord_embedding, context])\n",
      "Input \u001b[0;32mIn [81]\u001b[0m, in \u001b[0;36mcontext_embedding\u001b[0;34m(model, window, weighted_mean, weighted_distance, log_weight_distance)\u001b[0m\n\u001b[1;32m      2\u001b[0m chords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m w: w\u001b[38;5;241m.\u001b[39mchord\u001b[38;5;241m.\u001b[39msymbol \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, window)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# map chords to embedding\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m context \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(window))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weighted_mean:\n",
      "Input \u001b[0;32mIn [81]\u001b[0m, in \u001b[0;36mcontext_embedding.<locals>.<lambda>\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m      2\u001b[0m chords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m w: w\u001b[38;5;241m.\u001b[39mchord\u001b[38;5;241m.\u001b[39msymbol \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, window)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# map chords to embedding\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m context \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m c: model[c] \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_dim\u001b[49m), chords)))\n\u001b[1;32m      7\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(window))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weighted_mean:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Word2Vec' object has no attribute 'embedding_dim'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functools import partial\n",
    "\n",
    "X, y = embed_data(word2vec_model, train, context_size=5)\n",
    "\n",
    "X = np.stack(X)\n",
    "le = LabelEncoder().fit(sections)\n",
    "y = le.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42, stratify=y)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b6a132d-80ef-4e29-b097-9df79c5f27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69       200\n",
      "           1       0.59      0.52      0.55        81\n",
      "           2       0.40      0.50      0.45        46\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.46      0.42      0.44       115\n",
      "           5       0.53      0.56      0.55       119\n",
      "           6       0.59      0.55      0.57        47\n",
      "           7       0.69      0.73      0.71       285\n",
      "           8       0.25      0.17      0.20         6\n",
      "           9       0.83      0.82      0.82       775\n",
      "\n",
      "    accuracy                           0.71      1678\n",
      "   macro avg       0.50      0.50      0.50      1678\n",
      "weighted avg       0.71      0.71      0.71      1678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "parameters = { }\n",
    "\n",
    "clf = GridSearchCV(dt, parameters, cv=3, scoring=[\"f1_micro\", \"f1_macro\"], refit=\"f1_macro\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3164f072-93cc-483f-9999-ff1e5e77cd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47860203087723957"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = list()\n",
    "for sample in test:\n",
    "  target = le.transform([ann.section.lower() for ann in sample])\n",
    "  pred = segment_from_classifier(clf, word2vec_model, sample) \n",
    "  postprocess_prediction(le, section_p, pred)\n",
    "  f1.append(pairwise_metrics(target, pred))\n",
    "  \n",
    "np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f98428d-f3e2-4f26-9138-cdb0d2eea053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV 1/3] END max_depth=20, n_estimators=50; f1_macro: (test=0.545) f1_micro: (test=0.724) total time=   9.5s\n",
      "[CV 2/3] END max_depth=20, n_estimators=50; f1_macro: (test=0.534) f1_micro: (test=0.716) total time=   9.0s\n",
      "[CV 3/3] END max_depth=20, n_estimators=50; f1_macro: (test=0.556) f1_micro: (test=0.723) total time=   8.9s\n",
      "[CV 1/3] END max_depth=20, n_estimators=100; f1_macro: (test=0.562) f1_micro: (test=0.726) total time=  18.2s\n",
      "[CV 2/3] END max_depth=20, n_estimators=100; f1_macro: (test=0.547) f1_micro: (test=0.719) total time=  17.9s\n",
      "[CV 3/3] END max_depth=20, n_estimators=100; f1_macro: (test=0.556) f1_micro: (test=0.726) total time=  18.0s\n",
      "[CV 1/3] END max_depth=20, n_estimators=200; f1_macro: (test=0.554) f1_micro: (test=0.731) total time=  35.9s\n",
      "[CV 2/3] END max_depth=20, n_estimators=200; f1_macro: (test=0.541) f1_micro: (test=0.721) total time=  35.3s\n",
      "[CV 3/3] END max_depth=20, n_estimators=200; f1_macro: (test=0.557) f1_micro: (test=0.723) total time=  35.0s\n",
      "[CV 1/3] END max_depth=30, n_estimators=50; f1_macro: (test=0.585) f1_micro: (test=0.738) total time=   9.9s\n",
      "[CV 2/3] END max_depth=30, n_estimators=50; f1_macro: (test=0.553) f1_micro: (test=0.724) total time=   9.4s\n",
      "[CV 3/3] END max_depth=30, n_estimators=50; f1_macro: (test=0.571) f1_micro: (test=0.734) total time=   9.5s\n",
      "[CV 1/3] END max_depth=30, n_estimators=100; f1_macro: (test=0.606) f1_micro: (test=0.741) total time=  19.3s\n",
      "[CV 2/3] END max_depth=30, n_estimators=100; f1_macro: (test=0.563) f1_micro: (test=0.730) total time=  18.9s\n",
      "[CV 3/3] END max_depth=30, n_estimators=100; f1_macro: (test=0.582) f1_micro: (test=0.737) total time=  18.9s\n",
      "[CV 1/3] END max_depth=30, n_estimators=200; f1_macro: (test=0.597) f1_micro: (test=0.745) total time=  38.5s\n",
      "[CV 2/3] END max_depth=30, n_estimators=200; f1_macro: (test=0.574) f1_micro: (test=0.735) total time=  37.6s\n",
      "[CV 3/3] END max_depth=30, n_estimators=200; f1_macro: (test=0.576) f1_micro: (test=0.738) total time=  38.4s\n",
      "[CV 1/3] END max_depth=40, n_estimators=50; f1_macro: (test=0.570) f1_micro: (test=0.737) total time=   9.8s\n",
      "[CV 2/3] END max_depth=40, n_estimators=50; f1_macro: (test=0.555) f1_micro: (test=0.730) total time=   9.4s\n",
      "[CV 3/3] END max_depth=40, n_estimators=50; f1_macro: (test=0.577) f1_micro: (test=0.739) total time=   9.8s\n",
      "[CV 1/3] END max_depth=40, n_estimators=100; f1_macro: (test=0.603) f1_micro: (test=0.744) total time=  19.7s\n",
      "[CV 2/3] END max_depth=40, n_estimators=100; f1_macro: (test=0.563) f1_micro: (test=0.737) total time=  19.3s\n",
      "[CV 3/3] END max_depth=40, n_estimators=100; f1_macro: (test=0.585) f1_micro: (test=0.742) total time=  18.9s\n",
      "[CV 1/3] END max_depth=40, n_estimators=200; f1_macro: (test=0.605) f1_micro: (test=0.746) total time=  39.2s\n",
      "[CV 2/3] END max_depth=40, n_estimators=200; f1_macro: (test=0.565) f1_micro: (test=0.736) total time=  37.7s\n",
      "[CV 3/3] END max_depth=40, n_estimators=200; f1_macro: (test=0.582) f1_micro: (test=0.739) total time=  38.1s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79       200\n",
      "           1       0.77      0.60      0.68        81\n",
      "           2       0.51      0.39      0.44        46\n",
      "           3       0.50      0.25      0.33         4\n",
      "           4       0.60      0.51      0.55       115\n",
      "           5       0.77      0.55      0.64       119\n",
      "           6       0.71      0.51      0.59        47\n",
      "           7       0.80      0.79      0.79       285\n",
      "           8       0.33      0.17      0.22         6\n",
      "           9       0.80      0.92      0.86       775\n",
      "\n",
      "    accuracy                           0.78      1678\n",
      "   macro avg       0.66      0.54      0.59      1678\n",
      "weighted avg       0.77      0.78      0.77      1678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "parameters = { \"max_depth\": np.arange(20, 50, 10), \"n_estimators\": [50, 100, 200] }\n",
    "\n",
    "clf_rf = GridSearchCV(rf, parameters, cv=3, scoring=[\"f1_micro\", \"f1_macro\"], refit=\"f1_macro\", verbose=3)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf_rf.predict(X_test)\n",
    "print(classification_report(y_test, pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9ea29e7-36f1-470e-bd4f-2661cd914840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n28div/university/thesis/rohrmeier_pcfg/harte2vec/../segmentation/metrics.py:63: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  over_segmentation = max(0, 1 - (h_EA / (np.log2(N_P + 1e-50))))\n",
      "/home/n28div/university/thesis/rohrmeier_pcfg/harte2vec/../segmentation/metrics.py:63: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  over_segmentation = max(0, 1 - (h_EA / (np.log2(N_P + 1e-50))))\n"
     ]
    }
   ],
   "source": [
    "pairwise = list()\n",
    "under_over = list()\n",
    "for sample in test:\n",
    "  target = contigous_clusters(le.transform([ann.section.lower() for ann in sample]))\n",
    "  pred = segment_from_classifier(clf_rf, word2vec_model, sample)\n",
    "  pred = contigous_clusters(postprocess_prediction(le, section_p, pred))\n",
    "  pairwise.append(pairwise_metrics(target, pred))\n",
    "  under_over.append(under_over_segmentation(target, pred))\n",
    "  \n",
    "precision, recall, f1 = np.array(pairwise).mean(axis=0)\n",
    "under, over = np.array(under_over).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8bdc1dc6-edde-4ffb-aaf2-4914229f70d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.502198154978753,\n",
       " 0.78065718640416,\n",
       " 0.588264810859806,\n",
       " 0.7035475779025055,\n",
       " 0.47162620834015473)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, under, over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df79285-335e-47e6-8d65-7f033f56512b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea072cbb-88ff-4a71-a261-9c6ffc16bc50",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### As a classification problem: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac571a06-df23-47eb-b07b-66518753fe0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15093, 1678)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functools import partial\n",
    "\n",
    "X, y = embed_data(fasttext_model, train, context_size=5)\n",
    "\n",
    "X = np.stack(X)\n",
    "le = LabelEncoder().fit(sections)\n",
    "y = le.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42, stratify=y)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2609cf35-d279-4c38-a7b0-dceb270776c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV 1/3] END max_depth=20, n_estimators=50; f1_macro: (test=0.522) f1_micro: (test=0.714) total time=  10.7s\n",
      "[CV 2/3] END max_depth=20, n_estimators=50; f1_macro: (test=0.513) f1_micro: (test=0.714) total time=  10.4s\n",
      "[CV 3/3] END max_depth=20, n_estimators=50; f1_macro: (test=0.534) f1_micro: (test=0.713) total time=  10.4s\n",
      "[CV 1/3] END max_depth=20, n_estimators=100; f1_macro: (test=0.541) f1_micro: (test=0.719) total time=  19.9s\n",
      "[CV 2/3] END max_depth=20, n_estimators=100; f1_macro: (test=0.513) f1_micro: (test=0.706) total time=  26.0s\n",
      "[CV 3/3] END max_depth=20, n_estimators=100; f1_macro: (test=0.554) f1_micro: (test=0.712) total time=  21.1s\n",
      "[CV 1/3] END max_depth=20, n_estimators=200; f1_macro: (test=0.527) f1_micro: (test=0.717) total time=  39.1s\n",
      "[CV 2/3] END max_depth=20, n_estimators=200; f1_macro: (test=0.489) f1_micro: (test=0.707) total time=  39.7s\n",
      "[CV 3/3] END max_depth=20, n_estimators=200; f1_macro: (test=0.555) f1_micro: (test=0.712) total time=  39.7s\n",
      "[CV 1/3] END max_depth=30, n_estimators=50; f1_macro: (test=0.561) f1_micro: (test=0.730) total time=  10.9s\n",
      "[CV 2/3] END max_depth=30, n_estimators=50; f1_macro: (test=0.561) f1_micro: (test=0.720) total time=  10.4s\n",
      "[CV 3/3] END max_depth=30, n_estimators=50; f1_macro: (test=0.578) f1_micro: (test=0.726) total time=  11.2s\n",
      "[CV 1/3] END max_depth=30, n_estimators=100; f1_macro: (test=0.596) f1_micro: (test=0.735) total time=  23.0s\n",
      "[CV 2/3] END max_depth=30, n_estimators=100; f1_macro: (test=0.567) f1_micro: (test=0.723) total time=  22.3s\n",
      "[CV 3/3] END max_depth=30, n_estimators=100; f1_macro: (test=0.565) f1_micro: (test=0.726) total time=  22.2s\n",
      "[CV 1/3] END max_depth=30, n_estimators=200; f1_macro: (test=0.585) f1_micro: (test=0.732) total time=  44.8s\n",
      "[CV 2/3] END max_depth=30, n_estimators=200; f1_macro: (test=0.574) f1_micro: (test=0.728) total time=  47.9s\n",
      "[CV 3/3] END max_depth=30, n_estimators=200; f1_macro: (test=0.587) f1_micro: (test=0.732) total time=  46.6s\n",
      "[CV 1/3] END max_depth=40, n_estimators=50; f1_macro: (test=0.583) f1_micro: (test=0.737) total time=  11.9s\n",
      "[CV 2/3] END max_depth=40, n_estimators=50; f1_macro: (test=0.547) f1_micro: (test=0.719) total time=  11.8s\n",
      "[CV 3/3] END max_depth=40, n_estimators=50; f1_macro: (test=0.572) f1_micro: (test=0.726) total time=  10.6s\n",
      "[CV 1/3] END max_depth=40, n_estimators=100; f1_macro: (test=0.585) f1_micro: (test=0.736) total time=  20.4s\n",
      "[CV 2/3] END max_depth=40, n_estimators=100; f1_macro: (test=0.568) f1_micro: (test=0.728) total time=  19.7s\n",
      "[CV 3/3] END max_depth=40, n_estimators=100; f1_macro: (test=0.561) f1_micro: (test=0.724) total time=  20.9s\n",
      "[CV 1/3] END max_depth=40, n_estimators=200; f1_macro: (test=0.592) f1_micro: (test=0.736) total time=  45.6s\n",
      "[CV 2/3] END max_depth=40, n_estimators=200; f1_macro: (test=0.562) f1_micro: (test=0.725) total time=  44.7s\n",
      "[CV 3/3] END max_depth=40, n_estimators=200; f1_macro: (test=0.587) f1_micro: (test=0.729) total time=  42.6s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78       200\n",
      "           1       0.69      0.54      0.61        81\n",
      "           2       0.53      0.35      0.42        46\n",
      "           3       0.50      0.25      0.33         4\n",
      "           4       0.57      0.50      0.53       115\n",
      "           5       0.73      0.51      0.60       119\n",
      "           6       0.69      0.51      0.59        47\n",
      "           7       0.79      0.78      0.79       285\n",
      "           8       0.33      0.17      0.22         6\n",
      "           9       0.79      0.92      0.85       775\n",
      "\n",
      "    accuracy                           0.77      1678\n",
      "   macro avg       0.65      0.53      0.57      1678\n",
      "weighted avg       0.76      0.77      0.76      1678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "parameters = { \"max_depth\": np.arange(20, 50, 10), \"n_estimators\": [50, 100, 200] }\n",
    "\n",
    "clf_rf = GridSearchCV(rf, parameters, cv=3, scoring=[\"f1_micro\", \"f1_macro\"], refit=\"f1_macro\", verbose=3)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf_rf.predict(X_test)\n",
    "print(classification_report(y_test, pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1274dfd-9a2e-4931-9f43-4685b7504ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n28div/university/thesis/rohrmeier_pcfg/harte2vec/../segmentation/metrics.py:63: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  over_segmentation = max(0, 1 - (h_EA / (np.log2(N_P + 1e-50))))\n",
      "/home/n28div/university/thesis/rohrmeier_pcfg/harte2vec/../segmentation/metrics.py:63: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  over_segmentation = max(0, 1 - (h_EA / (np.log2(N_P + 1e-50))))\n",
      "/home/n28div/university/thesis/rohrmeier_pcfg/harte2vec/../segmentation/metrics.py:63: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  over_segmentation = max(0, 1 - (h_EA / (np.log2(N_P + 1e-50))))\n",
      "/home/n28div/university/thesis/rohrmeier_pcfg/harte2vec/../segmentation/metrics.py:63: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  over_segmentation = max(0, 1 - (h_EA / (np.log2(N_P + 1e-50))))\n"
     ]
    }
   ],
   "source": [
    "pairwise = list()\n",
    "under_over = list()\n",
    "for sample in test:\n",
    "  target = contigous_clusters(le.transform([ann.section.lower() for ann in sample]))\n",
    "  pred = segment_from_classifier(clf_rf, word2vec_model, sample)\n",
    "  pred = contigous_clusters(postprocess_prediction(le, section_p, pred))\n",
    "  pairwise.append(pairwise_metrics(target, pred))\n",
    "  under_over.append(under_over_segmentation(target, pred))\n",
    "  \n",
    "precision, recall, f1 = np.array(pairwise).mean(axis=0)\n",
    "under, over = np.array(under_over).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18bc3097-dc71-4c2d-a56f-84db543b685d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48690790879971463,\n",
       " 0.7605732692154131,\n",
       " 0.5725045982339887,\n",
       " 0.480847521621387,\n",
       " 0.4142533483699257)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, under, over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296099c-8329-4b99-9e0d-bbf3d8acc840",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using harte2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f049a1-11fe-4486-ab56-8b64ccad1873",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### As a classification problem: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "222c9180-2155-4c0d-a05d-4f4176815c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15093, 1678)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functools import partial\n",
    "\n",
    "X, y = embed_data(harte2vec, train, context_size=5)\n",
    "\n",
    "X = np.stack(X)\n",
    "le = LabelEncoder().fit(sections)\n",
    "y = le.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42, stratify=y)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95102e5f-d26a-4438-a6a2-114d18bebcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV 1/3] END n_estimators=100; f1_macro: (test=0.543) f1_micro: (test=0.734) total time=  37.6s\n",
      "[CV 2/3] END n_estimators=100; f1_macro: (test=0.523) f1_micro: (test=0.720) total time=  38.8s\n",
      "[CV 3/3] END n_estimators=100; f1_macro: (test=0.546) f1_micro: (test=0.730) total time=  38.3s\n",
      "[CV 1/3] END n_estimators=200; f1_macro: (test=0.533) f1_micro: (test=0.732) total time= 1.3min\n",
      "[CV 2/3] END n_estimators=200; f1_macro: (test=0.511) f1_micro: (test=0.719) total time= 1.3min\n",
      "[CV 3/3] END n_estimators=200; f1_macro: (test=0.562) f1_micro: (test=0.738) total time= 1.3min\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77       200\n",
      "           1       0.71      0.56      0.63        81\n",
      "           2       0.73      0.35      0.47        46\n",
      "           3       0.50      0.25      0.33         4\n",
      "           4       0.60      0.43      0.50       115\n",
      "           5       0.82      0.57      0.67       119\n",
      "           6       0.73      0.47      0.57        47\n",
      "           7       0.81      0.77      0.79       285\n",
      "           8       0.33      0.17      0.22         6\n",
      "           9       0.77      0.94      0.85       775\n",
      "\n",
      "    accuracy                           0.77      1678\n",
      "   macro avg       0.68      0.52      0.58      1678\n",
      "weighted avg       0.77      0.77      0.76      1678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf = RandomForestClassifier(class_weight={le.transform([k])[0]:v for k, v in sections_frequency.items()})\n",
    "parameters = { \"n_estimators\": [100, 200] }\n",
    "\n",
    "clf_rf = GridSearchCV(rf, parameters, cv=3, scoring=[\"f1_micro\", \"f1_macro\"], refit=\"f1_macro\", verbose=3)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf_rf.predict(X_test)\n",
    "print(classification_report(y_test, pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "370135d5-1863-421c-837b-3d857b432df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise = list()\n",
    "under_over = list()\n",
    "for sample in test:\n",
    "  target = contigous_clusters(le.transform([ann.section.lower() for ann in sample]))\n",
    "  pred = segment_from_classifier(clf_rf, harte2vec, sample)\n",
    "  pred = contigous_clusters(postprocess_prediction(le, section_p, pred))\n",
    "  pairwise.append(pairwise_metrics(target, pred))\n",
    "  under_over.append(under_over_segmentation(target, pred))\n",
    "  \n",
    "precision, recall, f1 = np.array(pairwise).mean(axis=0)\n",
    "under, over = np.array(under_over).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "98952522-d653-48c1-b5c6-25551903713a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5189973525998562,\n",
       " 0.7165302706138055,\n",
       " 0.5805084127648278,\n",
       " 0.6539111094267887,\n",
       " 0.49847541141217294)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, under, over"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
